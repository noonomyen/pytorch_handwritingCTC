{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from htr_crnn_ctc.datasource import IAM_CSVDataSource\n",
    "from htr_crnn_ctc.dataset import CTCDataset\n",
    "from htr_crnn_ctc.transforms import Rescale, ToRGB, ToTensor, Normalise\n",
    "from htr_crnn_ctc.dataloader import CTCDataLoader\n",
    "from htr_crnn_ctc.model import CTCModel\n",
    "from htr_crnn_ctc.learn import Learner\n",
    "\n",
    "from torchvision.transforms import Compose\n",
    "from torch import cuda, device as Device\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = Device(\"cuda\" if cuda.is_available() else \"cpu\")\n",
    "print(f\"dev: {dev}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvds = IAM_CSVDataSource(\n",
    "    file=\"index.csv\",\n",
    "    root_path=\"tmp\\\\dataset\\\\test\",\n",
    "    map_columns=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = [\n",
    "    Rescale(\n",
    "        output_size=(64, 800),\n",
    "        random_pad=True,\n",
    "        border_pad=(10, 40),\n",
    "        random_rotation=2,\n",
    "        random_stretch=1.2,\n",
    "        fill_space=False,\n",
    "        fill_threshold=200\n",
    "    ),\n",
    "    ToRGB(),\n",
    "    ToTensor(\n",
    "        rgb=True\n",
    "    ),\n",
    "    Normalise(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = CTCDataset(\n",
    "    data_source=csvds,\n",
    "    char_dict=None,\n",
    "    transform=Compose(trans)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of dataset: {len(ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds.char_dict)\n",
    "print()\n",
    "print(f\"Number of characters : {len(ds.char_dict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_data = open(\"tmp/models/test/train.log\", \"r\", encoding=\"utf-8\").readlines()\n",
    "data = []\n",
    "\n",
    "fit = 0\n",
    "old_epoch = 2\n",
    "sum_epoch = 0\n",
    "\n",
    "epochs = []\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "cer = []\n",
    "ier = []\n",
    "train_leven = []\n",
    "val_leven = []\n",
    "\n",
    "for idx, line in enumerate(src_data):\n",
    "    if (_ := line.strip()) != \"\\n\" and _ != \"\":\n",
    "        split = line.split(\" \")\n",
    "        sum_epoch += 1\n",
    "        epochs.append(sum_epoch)\n",
    "        train_loss.append(float(split[4]))\n",
    "        valid_loss.append(float(split[8]))\n",
    "        cer.append(float(split[11]))\n",
    "        ier.append(float(split[14]))\n",
    "        train_leven.append(float(split[17]))\n",
    "        val_leven.append(float(split[21]))\n",
    "\n",
    "metrics = {\n",
    "    \"train_loss\": (train_loss, \"Training Loss\"),\n",
    "    \"valid_loss\": (valid_loss, \"Validation Loss\"),\n",
    "    \"cer\": (cer, \"Character Error Rate\"),\n",
    "    \"ier\": (ier, \"Item Error Rate\"),\n",
    "    \"train_leven\": (train_leven, \"Training Levenshtein\"),\n",
    "    \"val_leven\": (val_leven, \"Validation Levenshtein\")\n",
    "}\n",
    "\n",
    "best_val_index = 0\n",
    "\n",
    "for idx in range(1, len(val_leven)):\n",
    "    if val_leven[best_val_index] >= val_leven[idx]:\n",
    "        best_val_index = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for key in [\"train_loss\", \"valid_loss\"]:\n",
    "    plt.plot(epochs, metrics[key][0], label=metrics[key][1])\n",
    "\n",
    "plt.title(\"Epoch vs Training Loss and Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for key in [\"cer\", \"ier\", \"train_leven\", \"val_leven\"]:\n",
    "    plt.plot(epochs, metrics[key][0], label=metrics[key][1])\n",
    "\n",
    "plt.title(\"Epoch vs Character Error Rate, Item Error Rate, Training and Validation Levenshtein\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Metrics\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Epochs                  {epochs[best_val_index]}\")\n",
    "print(f\"Training Loss           {train_loss[best_val_index]}\")\n",
    "print(f\"Validation Loss         {valid_loss[best_val_index]}\")\n",
    "print(f\"Character Error Rate    {cer[best_val_index]}\")\n",
    "print(f\"Item Error Rate         {ier[best_val_index]}\")\n",
    "print(f\"Training Levenshtein    {train_leven[best_val_index]}\")\n",
    "print(f\"Validation Levenshtein  {val_leven[best_val_index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = CTCDataLoader(\n",
    "    dataset=ds,\n",
    "    train_batch_size=120,\n",
    "    validation_batch_size=240,\n",
    "    validation_split=0.2,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    device=dev\n",
    ")\n",
    "\n",
    "model = CTCModel(\n",
    "    chan_in=3,\n",
    "    time_step=96,\n",
    "    feature_size=512,\n",
    "    hidden_size=512,\n",
    "    output_size=len(ds.char_dict) + 1,\n",
    "    num_rnn_layers=4,\n",
    "    rnn_dropout=0\n",
    ").to(dev)\n",
    "\n",
    "learn = Learner(\n",
    "    model=model,\n",
    "    dataloader=dl,\n",
    "    decode_map=None\n",
    ")\n",
    "\n",
    "learn.load(\n",
    "    f=\"tmp/models/test/model.pth\",\n",
    "    inv_f=\"tmp/models/test/decode_map.pk\",\n",
    "    load_decode=True,\n",
    "    keep_LSTM=True,\n",
    "    freeze_conv=False\n",
    ")\n",
    "\n",
    "learn.batch_predict(\n",
    "    dataloader=\"valid\",\n",
    "    show_img=True,\n",
    "    up_to=20\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
